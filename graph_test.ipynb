{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy\n",
    "import math\n",
    "import utils\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
    "from nuscenes.prediction import PredictHelper\n",
    "from nuscenes.prediction.input_representation.static_layers import StaticLayerRasterizer\n",
    "from nuscenes.prediction.input_representation.agents import AgentBoxesWithFadedHistory\n",
    "from nuscenes.prediction.input_representation.interface import InputRepresentation\n",
    "from nuscenes.prediction.input_representation.combinators import Rasterizer\n",
    "from nuscenes.eval.common.utils import quaternion_yaw\n",
    "from pyquaternion import Quaternion\n",
    "from nuscenes.map_expansion.map_api import NuScenesMap\n",
    "from nuscenes.map_expansion import arcline_path_utils\n",
    "from nuscenes.prediction.input_representation.static_layers import correct_yaw\n",
    "from matplotlib import pyplot as plt\n",
    "from nuscenes.map_expansion.bitmap import BitMap\n",
    "import threading\n",
    "from threading import Thread, Lock\n",
    "import multiprocessing as mp\n",
    "from utils import NuscenesUtil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 37.645 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 8.3 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nusc = NuScenes(version='v1.0-trainval', dataroot='E:\\\\nuScenesDataset\\\\v1.0-trainval_meta', verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "nusc_map = NuScenesMap(map_name='singapore-hollandvillage', dataroot='E:\\\\nuScenesDataset\\\\v1.0-trainval_meta')\n",
    "\n",
    "map_locs = ['singapore-onenorth', 'singapore-hollandvillage', 'singapore-queenstown', 'boston-seaport']\n",
    "maps = {item: NuScenesMap(map_name=item, dataroot='E:\\\\nuScenesDataset\\\\v1.0-trainval_meta') for item in map_locs}\n",
    "\n",
    "\n",
    "helper = PredictHelper(nusc)\n",
    "# static_layer_rasterizer = StaticLayerRasterizer(helper, meters_ahead=80, meters_left=50, meters_right=50)\n",
    "static_layer_rasterizer = StaticLayerRasterizer(helper)\n",
    "# agent_rasterizer = AgentBoxesWithFadedHistory(helper, seconds_of_history=1, meters_ahead=80, meters_left=50, meters_right=50)\n",
    "agent_rasterizer = AgentBoxesWithFadedHistory(helper, seconds_of_history=1)\n",
    "mtp_input_representation = InputRepresentation(static_layer_rasterizer, agent_rasterizer, Rasterizer())\n",
    "bitmap = BitMap(nusc_map.dataroot, nusc_map.map_name, 'basemap')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "challenges = get_prediction_challenge_split('train', 'E:\\\\nuScenesDataset\\\\v1.0-trainval_meta')\n",
    "target_instance_token, sample_token = challenges[900].split('_')\n",
    "# target_instance_token, sample_token = challenges[200].split('_')\n",
    "target_ann = helper.get_sample_annotation(target_instance_token, sample_token)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def sort_by_distance(item):\n",
    "    return item['distance']\n",
    "\n",
    "def get_surrounding_vehicle_by_distance(sample_token, target_instance_token, top_k):\n",
    "    \"\"\"\n",
    "    get all vehicles in a specific sample\n",
    "    :param sample_token:\n",
    "    :return: [(annotation_token, instance_token), ...]\n",
    "    \"\"\"\n",
    "    target_ann = helper.get_sample_annotation(target_instance_token, sample_token)\n",
    "    target_x, target_y = target_ann['translation'][0], target_ann['translation'][1]\n",
    "\n",
    "    # get vehicles with specific category\n",
    "    annotations = helper.get_annotations_for_sample(sample_token)\n",
    "    category_filter = NuscenesUtil.get_type_list()\n",
    "    result = [ann for ann in annotations if ann['category_name'] in category_filter]\n",
    "\n",
    "    # sort them by the distance to target vehicle and filte top 15\n",
    "    for item in result:\n",
    "        distance = NuscenesUtil.point_distance(item['translation'][0], item['translation'][1], target_x, target_y)\n",
    "        item['distance'] = distance\n",
    "\n",
    "    result.sort(key=sort_by_distance)\n",
    "    result = result[:top_k]\n",
    "    result = [item['token'] for item in result]\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_vehicles_ann_token_in_past(ann_token, time_horizon):\n",
    "    \"\"\"\n",
    "    get annotation token of vehicles in the past\n",
    "    :param ann_token: annotation token of target vehicle\n",
    "    :param time_horizon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ann = nusc.get('sample_annotation', ann_token)\n",
    "    instance_token, sample_token = ann['instance_token'], ann['sample_token']\n",
    "    past_ann = helper.get_past_for_agent(instance_token, sample_token, time_horizon, False, False)\n",
    "    past_ann_token = [ann['token'] for ann in past_ann]\n",
    "    return past_ann_token\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# node feature\n",
    "def generate_node_feature(get_ann_by_index, target_instance_token, target_sample_token):\n",
    "    node_features = []\n",
    "    node_num = len(get_ann_by_index)\n",
    "    target_ann = helper.get_sample_annotation(target_instance_token, target_sample_token)\n",
    "    target_x, target_y, target_yaw = target_ann['translation'][0], target_ann['translation'][1], NuscenesUtil.get_correct_yaw(target_ann['rotation'])\n",
    "    # the positions of all of vehicles is relative to the position of target vehicle in the last timestep\n",
    "    for node_id in range(node_num):\n",
    "        ann_token = get_ann_by_index[node_id]\n",
    "        ann = nusc.get('sample_annotation', ann_token)\n",
    "        # position\n",
    "        x, y, yaw = ann['translation'][0], ann['translation'][1], NuscenesUtil.get_correct_yaw(ann['rotation'])\n",
    "        if ann_token != target_ann['token']:\n",
    "            x, y, yaw = NuscenesUtil.align_coordinate(target_x, target_y, target_yaw, x, y, yaw)\n",
    "        else:\n",
    "            x, y, yaw = 0, 0, 0\n",
    "        # velocity, acceleration, type\n",
    "        velocity = helper.get_velocity_for_agent(ann['instance_token'], ann['sample_token'])\n",
    "        acceleration = helper.get_acceleration_for_agent(ann['instance_token'], ann['sample_token'])\n",
    "        type = NuscenesUtil.type_with_one_hot_encoding(ann['category_name'])\n",
    "        # construct feature by position, velocity, acceleration and type\n",
    "        feature = [x, y, yaw, velocity, acceleration]\n",
    "        feature.extend(type)\n",
    "        node_features.append(feature)\n",
    "\n",
    "    node_features = torch.tensor(node_features)\n",
    "    node_features = torch.nan_to_num(node_features)\n",
    "    return node_features\n",
    "\n",
    "# edge feature\n",
    "def generate_edge_feature(edges, node_features):\n",
    "    edge_features = torch.zeros(len(edges), 5)\n",
    "    for index, edge in enumerate(edges):\n",
    "        from_node, to_node = edge\n",
    "        feature = node_features[from_node][:5] - node_features[to_node][:5]\n",
    "        edge_features[index][:] = feature\n",
    "    return edge_features\n",
    "\n",
    "def generate_vehicle_graph(challenge):\n",
    "    target_instance_token, target_sample_token = challenge.split('_')\n",
    "    target_ann = helper.get_sample_annotation(target_instance_token, target_sample_token)\n",
    "    # generate graph\n",
    "    # node\n",
    "    # get all vehicle in past sample\n",
    "    past = helper.get_past_for_agent(target_instance_token, target_sample_token, 5, False, False)\n",
    "    past_sample_token = [target_sample_token]\n",
    "    past_sample_token.extend([item['sample_token'] for item in past])\n",
    "    past_vehicles = [get_surrounding_vehicle_by_distance(sample_token, target_instance_token, 20) for sample_token in past_sample_token]\n",
    "\n",
    "    # generate node index where node is a specific vehicle in a specific sample\n",
    "    get_index_by_ann = {}\n",
    "    get_ann_by_index = {}\n",
    "    index = 0\n",
    "    for vehicles in past_vehicles:\n",
    "        for vehicle in vehicles:\n",
    "            get_index_by_ann[vehicle] = index\n",
    "            get_ann_by_index[index] = vehicle\n",
    "            index += 1\n",
    "\n",
    "    # edge\n",
    "    edges = []\n",
    "\n",
    "    # for the same timestep, connect surrounding vehicles with 5 directions to the target vehicle\n",
    "    for vehicles in past_vehicles:\n",
    "        for vehicle in vehicles:\n",
    "            ann = nusc.get('sample_annotation', vehicle)\n",
    "            instance_token, sample_token = ann['instance_token'], ann['sample_token']\n",
    "            surrounding_vehicles = NuscenesUtil.get_surrounding_vehicle(helper, nusc_map, instance_token, sample_token)\n",
    "            for key in surrounding_vehicles:\n",
    "                surrounding_vehicle = surrounding_vehicles[key]\n",
    "                surrounding_ann_token = surrounding_vehicle['token']\n",
    "                if surrounding_ann_token not in get_index_by_ann:\n",
    "                    continue\n",
    "                from_index, to_index = get_index_by_ann[surrounding_ann_token], get_index_by_ann[vehicle]\n",
    "                edges.append((from_index, to_index))\n",
    "\n",
    "    # for the vehicle in a specific timestep, connect it to itself and surrounding vehicles in the past 1 seconds\n",
    "    for vehicles in past_vehicles:\n",
    "        for vehicle in vehicles:\n",
    "            # get past annotation_token\n",
    "            past_ann_tokens = get_vehicles_ann_token_in_past(vehicle, 1)\n",
    "            # connect to itself and surrounding vehicles\n",
    "            for past_ann_token in past_ann_tokens:\n",
    "                if past_ann_token not in get_index_by_ann:\n",
    "                    continue\n",
    "                ann = nusc.get('sample_annotation', past_ann_token)\n",
    "                instance_token, sample_token = ann['instance_token'], ann['sample_token']\n",
    "                edges.append((get_index_by_ann[past_ann_token], get_index_by_ann[vehicle]))\n",
    "                surrounding_vehicles = NuscenesUtil.get_surrounding_vehicle(helper, nusc_map, instance_token, sample_token)\n",
    "                for key in surrounding_vehicles:\n",
    "                    surrounding_vehicle = surrounding_vehicles[key]\n",
    "                    surrounding_ann_token = surrounding_vehicle['token']\n",
    "                    if surrounding_ann_token not in get_index_by_ann:\n",
    "                        continue\n",
    "                    from_index, to_index = get_index_by_ann[surrounding_ann_token], get_index_by_ann[vehicle]\n",
    "                    edges.append((from_index, to_index))\n",
    "\n",
    "    node_features = generate_node_feature(get_ann_by_index, target_instance_token, target_sample_token)\n",
    "    edge_features = generate_edge_feature(edges, node_features)\n",
    "\n",
    "    return node_features, edge_features, edges, get_index_by_ann[target_ann['token']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([165, 14]), torch.Size([1061, 5]), 1061, 0)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features, edge_features, edges, target_node_index = generate_vehicle_graph(challenges[3100])\n",
    "node_features.shape, edge_features.shape, len(edges), target_node_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32186/32186 [3:40:10<00:00,  2.44it/s]   \n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for challenge in tqdm.tqdm(challenges):\n",
    "    node_features, edge_features, edges, target_node_index = generate_vehicle_graph(challenge)\n",
    "    result[challenge] = (node_features, edge_features, edges, target_node_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "torch.save(result, './preprocess_vehicle_graph/train.data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9041/9041 [1:20:29<00:00,  1.87it/s]  \n"
     ]
    }
   ],
   "source": [
    "challenges = get_prediction_challenge_split('val', 'E:\\\\nuScenesDataset\\\\v1.0-trainval_meta')\n",
    "result = {}\n",
    "for challenge in tqdm.tqdm(challenges):\n",
    "    node_features, edge_features, edges, target_node_index = generate_vehicle_graph(challenge)\n",
    "    result[challenge] = (node_features, edge_features, edges, target_node_index)\n",
    "torch.save(result, './preprocess_vehicle_graph/test.data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_data = torch.load('./preprocess_vehicle_graph/train.data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  4.8726e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.2686e+00,  1.3640e+00,  1.5527e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.4878e+00,  6.9412e+00,  1.6399e+00,  2.1266e-02,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.0878e+01, -3.3116e+00,  4.7058e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.1160e+01,  3.2221e+00,  4.7528e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.5764e+00,  1.2581e+01,  1.5701e+00,  3.1249e-02,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.1040e+01,  8.6924e+00,  4.6830e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.5023e+00,  1.7492e+01,  1.5876e+00,  5.8257e-02,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.0916e+01,  1.4930e+01,  4.6655e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00],\n         [-1.0885e+01,  2.4959e+01,  4.7179e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 2.2921e-01,  2.9543e+01,  1.5752e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.2336e+00, -4.3350e+01,  1.5305e+00,  6.0275e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 1.0675e+01,  4.2952e+01,  3.3760e+00,  2.0597e-02,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 1.6861e+01,  4.4035e+01,  3.3201e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.6568e+01,  5.7577e+01,  3.8903e-02,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-3.3205e-02, -2.4354e+00,  1.5752e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.8663e+00, -5.0117e+00,  1.5701e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.2686e+00,  1.3640e+00,  1.5527e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.4772e+00,  6.9412e+00,  1.6399e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.0878e+01, -3.3116e+00,  4.7058e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.1160e+01,  3.2221e+00,  4.7528e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.5760e+00,  1.2596e+01,  1.5701e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.1040e+01,  8.6924e+00,  4.6830e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 3.4866e+00,  1.7467e+01,  1.5876e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.0916e+01,  1.4930e+01,  4.6655e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00],\n         [-1.0885e+01,  2.4959e+01,  4.7179e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 2.2921e-01,  2.9543e+01,  1.5752e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.3374e+00, -4.6361e+01,  1.5305e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 1.0685e+01,  4.2954e+01,  3.3760e+00,  0.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n        dtype=torch.float64),\n tensor([[-3.3205e-02, -2.4354e+00,  1.5752e+00, -4.8726e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.0630e-02, -1.9309e-05,  0.0000e+00, -2.1266e-02,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-4.0465e-04,  1.5615e-02,  0.0000e+00, -3.1249e-02,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.5760e-02, -2.4487e-02,  0.0000e+00, -5.8257e-02,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n         [-1.0384e-01, -3.0112e+00,  0.0000e+00, -6.0275e+00,  0.0000e+00],\n         [ 1.0062e-02,  2.1819e-03,  0.0000e+00, -2.0597e-02,  0.0000e+00]]),\n [(15, 0),\n  (17, 1),\n  (18, 2),\n  (19, 3),\n  (20, 4),\n  (21, 5),\n  (22, 6),\n  (23, 7),\n  (24, 8),\n  (25, 9),\n  (26, 10),\n  (27, 11),\n  (28, 12)],\n 0)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge = challenges[0]\n",
    "train_data[challenge]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120, 191, 1.59\n",
      "165, 1183, 7.17\n",
      "131, 213, 1.63\n",
      "105, 589, 5.61\n",
      "42, 42, 1.00\n",
      "165, 252, 1.53\n",
      "165, 260, 1.58\n",
      "4, 2, 0.50\n",
      "165, 345, 2.09\n",
      "74, 108, 1.46\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    challenge = random.choice(challenges)\n",
    "    node_features, edge_features, edges, tar = train_data[challenge]\n",
    "    num_node, num_edge = len(node_features), len(edges)\n",
    "    print(f'{num_node}, {num_edge}, {num_edge / num_node:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}